{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cleaning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, json, pickle, string\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "MainPath = 'C:/Users/Francesco/Desktop/chatbot/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve Babel Domains Triples\n",
    "if 'babeldomains3.json' not in os.listdir(MainPath + 'chatbot_data/others'):\n",
    "    # open file from Babel Domains\n",
    "    path = 'BabelDomains_full/BabelDomains/babeldomains_babelnet.txt'\n",
    "    with open(path, 'r') as f:\n",
    "        lstBabelDomains = [x.strip().split('\\t') for x in f.readlines()]\n",
    "    # Keeping only domains with no-disambiguation\n",
    "    only3 = list(filter(lambda x: len(x) == 3, lstBabelDomains))\n",
    "    dic_only3 = {x[0]: x[1] for x in only3}\n",
    "    with open(MainPath + 'chatbot_data/others/babeldomains3.json', 'w') as f:\n",
    "        json.dump(dic_only3, f)\n",
    "else:\n",
    "    with open(MainPath + 'chatbot_data/others/'+'babeldomains3.json', 'r') as f: dic_only3 = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Load the Data downloaded from KBS Server\n",
    "with open('kbs_entries.json', 'r') as f: new = f.read()\n",
    "json_kbs1M = json.loads(new)\n",
    "dic_kbs1M = {x['HASH']: x for x in json_kbs1M}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obs: 1128884\n"
     ]
    }
   ],
   "source": [
    "print('Total number of obs: %s' %len(dic_kbs1M))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remove observations without BabelNet IDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "noBabelID = list(filter(lambda x: 'bn:' not in dic_kbs1M[x]['c1'] or 'bn:' not in dic_kbs1M[x]['c2'],\n",
    "       dic_kbs1M.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obs: 949185\n",
      "Observations with No-Babel ID for one of the concepts: 179699\n",
      "Portion of discarded observations: 0.15918287441402304\n"
     ]
    }
   ],
   "source": [
    "print('Total number of obs: %s' %(len(dic_kbs1M)- len(noBabelID)))\n",
    "print ('Observations with No-Babel ID for one of the concepts: %s'%len(noBabelID))\n",
    "print ('Portion of discarded observations: %s'%(len(noBabelID)/len(dic_kbs1M)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "newKeys = set(list(dic_kbs1M.keys())) - set(noBabelID)\n",
    "dic_kbs1M = {x : dic_kbs1M[x] for x in newKeys}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>TotalConcepts</th>\n",
       "      <th>Frequency</th>\n",
       "      <th>Ratio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>843074</td>\n",
       "      <td>0.888208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>20526</td>\n",
       "      <td>0.021625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>19703</td>\n",
       "      <td>0.020758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>16219</td>\n",
       "      <td>0.017087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>11946</td>\n",
       "      <td>0.012586</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  TotalConcepts Frequency     Ratio\n",
       "0             2    843074  0.888208\n",
       "1             3     20526  0.021625\n",
       "2             4     19703  0.020758\n",
       "3             5     16219  0.017087\n",
       "4             6     11946  0.012586"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Distribution of the number of concepts involved in each question\n",
    "countBabelID = Counter([dic_kbs1M[x]['c1'].count('bn:') + dic_kbs1M[x]['c2'].count('bn:') for x in dic_kbs1M] )\n",
    "tuplesCounter = sorted(countBabelID.items(), key = lambda x: x[1], reverse = True)\n",
    "dfCounter = pd.DataFrame.from_records(tuplesCounter, columns=[['TotalConcepts', 'Frequency']])\n",
    "dfCounter['Ratio'] = dfCounter['Frequency']/len(dic_kbs1M)\n",
    "dfCounter.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since more than the 88% of the observations involve only 2 concept, we prefer to discard all the others."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HashConceptsRaw = [(hash_code,d['c1'], d['c2']) for (hash_code, d) in dic_kbs1M.items() \n",
    "                  if d['c1'].count('bn:') == 1 and d['c2'].count('bn:') == 1]\n",
    "HashConcepts = [(hash_code, 'bn:' + c1.split('bn:')[1][:9], 'bn:' + c2.split('bn:')[1][:9]) \n",
    "                for (hash_code, c1, c2) in HashConceptsRaw]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obs: 843074\n",
      "Observations with more than 2 concepts: 106111\n",
      "Portion of discarded observations: 0.11179169498043062\n"
     ]
    }
   ],
   "source": [
    "print('Total number of obs: %s' %len(HashConcepts))\n",
    "print ('Observations with more than 2 concepts: %s'%(len(dic_kbs1M)- len(HashConcepts)))\n",
    "print ('Portion of discarded observations: %s'%(1 - len(HashConcepts)/len(dic_kbs1M)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, looking at the Domains already retrived, we connect (C1, C2) - Domains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "HashConceptsDomains = {}\n",
    "for (hash_code, c1, c2) in HashConcepts:\n",
    "    new_d = []\n",
    "    if c1 in dic_only3:\n",
    "        new_d.append(dic_only3[c1])\n",
    "    if c2 in dic_only3:\n",
    "        new_d.append(dic_only3[c2])\n",
    "    new_d = list(set(new_d))\n",
    "    if new_d != []:\n",
    "        HashConceptsDomains[(hash_code, c1, c2)] = new_d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of obs: 658946\n",
      "Observations without edge Domain - (C1, C2): 184128\n",
      "Portion of discarded observations: 0.2794280563202447\n"
     ]
    }
   ],
   "source": [
    "print('Total number of obs: %s' %len(HashConceptsDomains))\n",
    "print('Observations without edge Domain - (C1, C2): %s'%(len(HashConcepts) - len(HashConceptsDomains)))\n",
    "print ('Portion of discarded observations: %s'%(len(HashConcepts)/len(HashConceptsDomains) - 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We lost the 28% of observations, since they don't have an association with any domain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IdxRelations, IdxDomains and DataDiz saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "path = MainPath + 'BabelDomains_full/'\n",
    "with open(path + 'domain_list.txt', 'r') as f: lst_domains = list(map(lambda x: x.strip(), \n",
    "                                                                      f.readlines()))\n",
    "\n",
    "IdxDomains = {value: idx for idx, value in enumerate(lst_domains)}\n",
    "with open(MainPath +'chatbot_data/others/IdxDomains.json', 'w') as f: json.dump(IdxDomains, f)\n",
    "\n",
    "DataDiz = {}\n",
    "for hc in HashConceptsDomains:\n",
    "    obs = {\n",
    "        'question' : dic_kbs1M[hc[0]]['question'],\n",
    "        'relation' : dic_kbs1M[hc[0]]['relation'],\n",
    "        'domain' : HashConceptsDomains[hc],\n",
    "        'answer' : dic_kbs1M[hc[0]]['answer'],\n",
    "        'concepts': (hc[1], hc[2])\n",
    "    }\n",
    "    DataDiz[hc[0]] = obs    \n",
    "    \n",
    "IdxRelations = {value: idx for idx, value in enumerate(sorted(set([DataDiz[hashcode]['relation'] \n",
    "                                                         for hashcode in DataDiz])))}\n",
    "with open(MainPath +'chatbot_data/others/IdxRelations.json', 'w') as f: json.dump(IdxRelations, f)\n",
    "\n",
    "\n",
    "\n",
    "path = MainPath + 'chatbot_data/others/'\n",
    "with open(path + 'DataDiz.json', 'w') as outfile: json.dump(DataDiz, outfile)\n",
    "pickle.dump(HashConceptsRaw, open(path + 'HashConceptsRaw.p', \"wb\" ))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
