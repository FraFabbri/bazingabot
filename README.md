# BazingaBot - A simple but effective knowledge-bot

## Intro
The bot has been tought to be able to answer to (almost...) all the queries in the dataset (330000 distinct observations). 
A *distinct observation* is a unique tuple of relation-domain-question. The structure has been tought trying to exploit as much as possible the **metadata** provided for the project. 

Using other types of data would be possible, but first we should need to adapt these to our setting (using Babelfy and BabelDomains).

## Model
The preditions obtained by the bot are the result of a long process where:

1. We needed to apply a specific word embedding because of the metadata used, without exploiting exernal resources.

2. I couldn't apply a Seq2Seq at the word-level for the generic *open-ended questions*, which would be more reasonable (the model would be able to chatch the relations between the words and not between the characters) because of the limits of the hardware.

3. during the training step I find out that, applying a Seq2Seq Model at the character-level, the time needed to produce the right answers is directly proportional to both the number of distinct observations and the times we repeat a tuple in the dataset, but with different factors of approximation.

## Code and Directories

### 1. Directories
- */conversations:* we store all the conversations produced by the bot, one folder per conversation
- */data:* data used for the predictions
- */models:* all the models produced (weights and useful training data)
- */modules*: all the functions and NN models used for building the bot
- */others*: data useful through the project
- */processedKBS*: preprocessing and cleaning 
- */prediction_scripts*: the codes used to train the 4 models
- */examples*: 200 observations predicted in order to show the quality of the predicted answers
- */settings*: it contains the last_id needed to retrieve the data from Telegram


### 2. How to run the chatbot (main folder)

- *generate_data.py*: it generates some examples of the observations used in the models
- *main.py*: run the chatbot
- *retrieve_new_data.py*: extract knowledge from data generated by the enriching
- *tester_querying.py*: to test the prediction of the model

For chatting and running the bot on your own laptop you just need to run the main file and start a conversation on telegram. (username: @bazinga_bot).

For any kind of issue or error you just need to clean the "conversations" folder.

### 3.  Test the model
In order to test the model we just run the script tester_querying as in the example below:

```{r, engine = "bash", eval = FALSE}
python tester_querying "What family do cytoplasm belong to | Biology | SPECIALIZATION"

```

**You can find a detailed description of the whole project in the report folder**

p.s. remember the quotes!
